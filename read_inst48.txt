# Instructions47 - LLM Provider Integration & Salesforce Org Placeholder

## Summary
These instructions build upon the work completed in **instructions46** to deliver the final set of improvements for the Agentic Analytics Studio (AAS) project.  They add support for configurable AI/LLM providers, prepare for integration of the forthcoming Salesforce org, and improve the UI and developer experience.  Apply these tasks on top of the current GitHub repository (**Agentic‑Analytics‑Studio**) after syncing with the local repo.  

> **Important:** Do **not** commit any secrets (such as `.env` contents or API keys) to version control.  Use the provided `.env.example` file to document required variables and keep your `.env` local.

## 1. Add LLM Provider Support

### 1.1 Environment variables
Introduce the following variables in **`.env.example`** and update your local `.env` accordingly:

| Variable              | Example value                          | Description |
|-----------------------|----------------------------------------|-------------|
| `LLM_PROVIDER`       | `openai` \| `ollama` \| `none` (default)| Determines which engine to use for rationale generation. |
| `OPENAI_API_KEY`     | `sk-...`                                | Secret key if using OpenAI. Already added locally for the demo. |
| `OPENAI_MODEL`       | `gpt-4-turbo`                          | Optional; override to pick a specific OpenAI model. |
| `OLLAMA_BASE_URL`    | `http://localhost:11434/api`           | Base URL for the Ollama server (only needed if using `ollama`). |
| `OLLAMA_MODEL`       | `llama3` \| `llama2`                   | Model name served by Ollama. |
| `SF_USERNAME`        | `<supplied later>`                     | Placeholder for Salesforce username. |
| `SF_PASSWORD`        | `<supplied later>`                     | Placeholder for Salesforce password. |
| `SF_SECURITY_TOKEN`  | `<supplied later>`                     | Placeholder for Salesforce security token. |

Ensure `.env.example` includes these with comments describing their purpose.  Commit `.env.example` but **never** commit your actual `.env`.

### 1.2 Rationale provider abstraction
Refactor the `generate_rationale` function in your agent base class to check `LLM_PROVIDER` at runtime and call the appropriate provider:

1. **OpenAI:** If `LLM_PROVIDER=openai` and `OPENAI_API_KEY` is set, call the OpenAI API using the model specified by `OPENAI_MODEL` (default to `gpt-4-turbo`).  Limit the prompt and `max_tokens` to produce a short, clear sentence.  Handle API errors gracefully and log failures.
2. **Ollama:** If `LLM_PROVIDER=ollama` and both `OLLAMA_BASE_URL` and `OLLAMA_MODEL` are set, call the Ollama API via HTTP (`POST ${OLLAMA_BASE_URL}/generate`) with a JSON body containing the model and prompt.  Limit token count and timeouts.  Handle errors gracefully and log them.
3. **None / fallback:** If `LLM_PROVIDER=none` or no credentials are provided, generate a deterministic rule‑based explanation (e.g., summarise the key metric that triggered the action).  This ensures the app always returns a rationale.

Add unit tests (or simple test scripts) covering each branch and ensure no provider call throws uncaught exceptions.  Use proper logging (e.g., via the Python `logging` module) to record which provider was used and any fallback events.

### 1.3 Update the Action model and UI
Make sure the `Action` dataclass/model includes two fields: `reasoning` (string) and `impact_score` (float).  Populate `reasoning` using the new `generate_rationale` function.  In the frontend:

* Display a small status chip (e.g., in the header or sidebar) showing which LLM provider is active: **“LLM: OpenAI”**, **“LLM: Ollama”**, or **“LLM: Off”**.
* Show the `reasoning` text on each action card or detail view (for instance, beneath the action description).  If the fallback reason is used, still display it so users understand why the action was recommended.

## 2. Prepare for the new Salesforce Org integration

### 2.1 Placeholder credentials
The hackathon organisers will soon supply a Salesforce org with credentials.  Once received, set them in `.env` using `SF_USERNAME`, `SF_PASSWORD`, and `SF_SECURITY_TOKEN`.  Until then:

* Ensure that `SalesforceClient` and any agent that relies on it (e.g., `PipelineLeakageAgent`) gracefully fall back to a stubbed client when these variables are missing.  Provide clear log messages and UI indications such as **“Execution: Mock (Salesforce creds not set)”**.
* Document this behaviour in the README so judges know why tasks may appear simulated.

### 2.2 Consistent naming
Standardise on `SF_USERNAME`, `SF_PASSWORD`, and `SF_SECURITY_TOKEN` throughout the codebase.  Remove older variable names like `SALESFORCE_USERNAME` or others.  Update tests, docs, and any command‑line scripts to reference the new names.

### 2.3 Updating the executor
In any agent that creates Salesforce tasks (e.g., `pipeline_leakage_agent.py`), ensure that tasks are only created when the Salesforce client is active.  Store the returned `task_id` on the `Action`.  When stubbed, generate a mock ID, such as `"mock_task_" + uuid4().hex`.

## 3. UI and Developer Experience polish

### 3.1 README & demo updates
Revise the README to highlight the new features:

* Explain the LLM provider abstraction and list supported providers (`openai`, `ollama`, `none`).
* Provide instructions for setting up the `.env` file, including both Salesforce and LLM variables.  Stress the importance of not committing secrets.
* Describe how the app behaves in “mock mode” for Salesforce and when no LLM is available.  Include a table or bullet list summarising the environment variables.
* Add a “Run Summary” explanation to illustrate the business metrics returned by each play (e.g., `value_at_risk`, `expected_revenue_recovered`), and mention the new impact‑sorted actions.
* Verify that build and deployment instructions (`npm run build`, etc.) still work after your changes.

### 3.2 Demo video script adjustments
When preparing the demo video:

* Show the status chip for the LLM provider and mention which provider is in use.  Emphasise that the architecture is LLM‑agnostic and that enterprises can swap providers (OpenAI vs. Ollama) or opt for no AI.
* Demonstrate the new rationale appearing alongside each action and highlight that actions are now sorted by financial impact.  Mention the impact metrics and the fallback explanation if no AI is used.
* Indicate the current execution status (Mock vs. Live) when approving actions.  When the Salesforce credentials are set, show the real `task_id` returned from Salesforce.

### 3.3 Logging & metrics capture
Ensure that approved actions continue to be logged to `data/action_feedback_log.csv` as implemented.  Consider adding a timestamp and the LLM provider used to each log entry for future analysis.  This will help in evaluating which provider yields better action acceptance rates.

## 4. Security & version control

* Confirm that `.gitignore` excludes `.env` and any other secret files.  Verify that your local `.env` has the OpenAI key but has not been committed.
* Never place API keys or Salesforce credentials in client‑side code; keep all provider calls in the backend.
* Provide a short note in the README about using a secret manager or environment variables for production deployments.

## 5. Testing & validation

* After implementing these changes, run your tests or manually exercise each play:
  1. Set `LLM_PROVIDER=openai` with a valid `OPENAI_API_KEY` and observe that rationales are generated by OpenAI.
  2. Set `LLM_PROVIDER=ollama` with valid `OLLAMA_BASE_URL` and `OLLAMA_MODEL` and verify that rationales come from the local LLM.
  3. Set `LLM_PROVIDER=none` and ensure that a deterministic fallback rationale is displayed.
  4. Omit Salesforce variables and verify that the system stays in mock mode, displaying the correct status.
  5. When Salesforce credentials arrive, set them in `.env` and confirm tasks are created successfully with real `task_id`s.

* Validate that the UI displays the LLM status, the rationale, and the correct impact ordering for actions.  Check that the app still feels responsive and the additional API calls do not introduce significant latency.

---

Deliver this `instructions.md` file inside a zip archive named **`instructions47.zip`**.  This document supersedes previous instructions regarding AI/LLM integration and outlines the work needed to incorporate the forthcoming Salesforce org.  Follow these guidelines to bring the Agentic Analytics Studio project to a polished, submission‑ready state.